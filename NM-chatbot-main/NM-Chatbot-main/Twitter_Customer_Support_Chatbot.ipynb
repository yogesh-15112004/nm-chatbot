{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa6c5873",
   "metadata": {},
   "source": [
    "# Revolutionizing Customer Support with an Intelligent Chatbot (Using Twitter Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012db6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install transformers\n",
    "!pip install pandas\n",
    "!pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece758e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce794f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the Twitter Customer Support Dataset\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f09ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "# Note: Replace 'customer_support_tweets.csv' with the actual uploaded filename if different\n",
    "df = pd.read_csv('customer_support_tweets.csv')\n",
    "\n",
    "# Explore Dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a49179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Dataset\n",
    "# Focus on inbound customer queries only\n",
    "customer_queries = df[df['inbound'] == True]['text'].dropna().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-trained Conversational AI Model\n",
    "model_name = \"facebook/blenderbot-400M-distill\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fee349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Chatbot Response Function\n",
    "def customer_support_response(user_input):\n",
    "    inputs = tokenizer([user_input], return_tensors=\"pt\", truncation=True)\n",
    "    outputs = model.generate(**inputs, max_length=100)\n",
    "    reply = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return reply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911b4141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Gradio Web Interface\n",
    "iface = gr.Interface(\n",
    "    fn=customer_support_response,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Twitter Customer Support AI Chatbot\",\n",
    "    description=\"Ask your customer support questions â€” Powered by Twitter customer support dataset and Gen AI\"\n",
    ")\n",
    "\n",
    "# Launch the App\n",
    "iface.launch(debug=True)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
